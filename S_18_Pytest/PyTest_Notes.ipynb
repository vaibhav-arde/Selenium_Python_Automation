{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **S18 : Pytest**\n",
    "\n",
    "## **Pytest Testing Framework**\n",
    "- Install pytest : pip3 install pytest\n",
    "- Naming convensions to follow for Pytest tests\n",
    "- Running pytests from command line and VSCode\n",
    "- Running selected test files using pytest\n",
    "- Running selected test methods based on matching keywords\n",
    "- Pytest Tags Mechanism to run tests based on functionality\n",
    "- Failing and Skipping tests with Annotations using Pytest\n",
    "- What are fixtures and importance of their Hooks in Pytest\n",
    "- How fixtures can be configured in Conftest file for better readability\n",
    "- Different scopes of fixtures and their related annotations to setup Pre and Post conditions on the Test\n",
    "- How parameterization can be achieved for tests with multiple sets of data\n",
    "- How to pass command line arguments into Pytests\n",
    "- HTML report generation for pytests execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Naming convensions to follow for Pytest tests**\n",
    "\n",
    "When writing tests in Pytest, following proper naming conventions is essential for readability, consistency, and automatic discovery of tests by the Pytest framework. Below are the recommended naming conventions to follow for Pytest tests:\n",
    "\n",
    "### 1. **Test File Names**:\n",
    "- Test files should be named in a way that Pytest can automatically discover them.\n",
    "- **Convention**: Files should either:\n",
    "  - **Start with** `test_` (e.g., `test_example.py`), or\n",
    "  - **End with** `_test.py` (e.g., `example_test.py`).\n",
    "\n",
    "This ensures Pytest recognizes them as test files when scanning your codebase.\n",
    "\n",
    "### 2. **Test Function Names**:\n",
    "- Test function names should be descriptive and clearly indicate the expected behavior or the functionality being tested.\n",
    "- **Convention**: Test function names should **start with** `test_` (e.g., `test_addition_function` or `test_login_valid_credentials`).\n",
    "\n",
    "By starting with `test_`, Pytest can automatically discover and run these functions.\n",
    "\n",
    "### 3. **Test Class Names**:\n",
    "- Although Pytest does not require test classes, if you use them to organize related tests, the class name should also follow certain conventions.\n",
    "- **Convention**: Class names should start with `Test` (e.g., `TestUserLogin`, `TestMathOperations`). \n",
    "  - Unlike test functions, you do **not** need to prefix each method in a test class with `test_` if the class name starts with `Test`.\n",
    "\n",
    "Note: Pytest does not require test classes to inherit from `unittest.TestCase`.\n",
    "\n",
    "### 4. **Naming Parameters for Parametrized Tests**:\n",
    "- When using `@pytest.mark.parametrize`, ensure that parameter names are meaningful and related to the functionality being tested.\n",
    "- **Example**:\n",
    "  ```python\n",
    "  @pytest.mark.parametrize(\"input, expected\", [\n",
    "      (1, 2),\n",
    "      (3, 4)\n",
    "  ])\n",
    "  def test_add(input, expected):\n",
    "      assert input + 1 == expected\n",
    "  ```\n",
    "\n",
    "### 5. **Fixture Naming**:\n",
    "- Fixtures in Pytest provide a mechanism for setup and teardown. Fixtures should have descriptive and short names that reflect the resource they are setting up.\n",
    "- **Convention**: Use snake_case for fixture names (e.g., `db_connection`, `temporary_file`).\n",
    "- **Example**:\n",
    "  ```python\n",
    "  @pytest.fixture\n",
    "  def db_connection():\n",
    "      return Database.connect()\n",
    "  ```\n",
    "\n",
    "### 6. **Constants Naming in Tests**:\n",
    "- If you're defining constants or mock data within your test, they should follow Python's constant naming convention: **ALL_CAPS** with underscores to separate words.\n",
    "- **Example**:\n",
    "  ```python\n",
    "  MAX_RETRIES = 3\n",
    "  VALID_USERNAME = \"test_user\"\n",
    "  ```\n",
    "\n",
    "### 7. **Test Naming for Expected Behavior**:\n",
    "- Test function names should convey the expected behavior or outcome. Include the condition being tested and the expected result in the function name for clarity.\n",
    "- **Convention**: Use the pattern `test_<functionality>_<expected_behavior>` (e.g., `test_login_success`, `test_addition_negative_numbers`, `test_search_no_results`).\n",
    "\n",
    "### 8. **Use Verbose Names**:\n",
    "- Avoid abbreviations or overly shortened names. Instead, use names that clearly describe the test's purpose.\n",
    "- **Example**:\n",
    "  - Prefer `test_calculate_total_with_discount()` over `test_calc_disc()`.\n",
    "  \n",
    "### 9. **Negative and Edge Case Test Naming**:\n",
    "- If you're testing for failure cases or edge conditions, explicitly include that in the test name.\n",
    "- **Convention**: Use words like `invalid`, `error`, `empty`, or `failure` in the test name.\n",
    "- **Example**:\n",
    "  ```python\n",
    "  def test_login_invalid_credentials():\n",
    "      pass\n",
    "\n",
    "  def test_add_empty_list():\n",
    "      pass\n",
    "  ```\n",
    "\n",
    "### 10. **Use Underscores Instead of CamelCase**:\n",
    "- Pytest prefers using `snake_case` for naming functions, files, and variables over `camelCase`, which is more common in other testing frameworks like Java's JUnit.\n",
    "- **Example**:\n",
    "  ```python\n",
    "  def test_calculate_total_cost():\n",
    "      pass\n",
    "  ```\n",
    "\n",
    "### Summary of Naming Conventions:\n",
    "- **Test files**: `test_*.py` or `*_test.py`\n",
    "- **Test functions**: `test_<description_of_test_case>()`\n",
    "- **Test classes**: `Test<ClassName>` (without `test_` prefix for class methods)\n",
    "- **Fixtures**: Use descriptive, snake_case names\n",
    "- **Constants**: ALL_CAPS with underscores\n",
    "- **Be descriptive**: Include expected behaviors in names\n",
    "\n",
    "Following these conventions ensures consistency and readability across your test suite, making your tests easier to maintain and more self-explanatory to collaborators.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Running pytests from VSCode**\n",
    "\n",
    "There are several ways to run individual tests in Visual Studio Code (VS Code) using plugins that support Pytest. One of the most popular plugins is **\"Python\"** by Microsoft, which includes support for running Python tests, including Pytest.\n",
    "\n",
    "### Steps to Run Single Pytest with VS Code:\n",
    "\n",
    "1. **Install the Python Extension**:\n",
    "   - Install the official **Python** extension for VS Code, which includes support for testing with Pytest.\n",
    "   - Go to the Extensions view in VS Code (`Ctrl + Shift + X`), search for \"Python\", and install it.\n",
    "\n",
    "2. **Configure Pytest in VS Code**:\n",
    "   - Open the **command palette** (`Ctrl + Shift + P`), then search for `Python: Configure Tests`.\n",
    "   - Select **Pytest** as your test framework.\n",
    "   - VS Code will automatically detect test files and configure them for Pytest.\n",
    "\n",
    "3. **Running a Single Test**:\n",
    "   After configuring Pytest in VS Code, you can run individual tests directly from the editor.\n",
    "\n",
    "   **Method 1: Run Test with CodeLens** (In-editor option)\n",
    "   - When you open a test file, you’ll notice small **Run Test** and **Debug Test** links above each test function. This feature is called **CodeLens**.\n",
    "   - Click **Run Test** above the individual test function to run that specific test.\n",
    "\n",
    "   **Method 2: Use Testing Sidebar**:\n",
    "   - In the activity bar on the left-hand side, click the **Testing** icon (flask icon).\n",
    "   - This will open the **Testing Panel**, where you can view all discovered tests.\n",
    "   - You can select individual tests and click the play button to run them.\n",
    "\n",
    "4. **Run Single Test from the Command Palette**:\n",
    "   - Open the command palette (`Ctrl + Shift + P`), and search for `Python: Run Tests`.\n",
    "   - Select a single test from the list to run it.\n",
    "\n",
    "### Example Configuration in VS Code:\n",
    "\n",
    "In your workspace folder, you can also create a `settings.json` file to configure Pytest:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"python.testing.pytestArgs\": [\"tests\"],\n",
    "    \"python.testing.unittestEnabled\": false,\n",
    "    \"python.testing.nosetestsEnabled\": false,\n",
    "    \"python.testing.pytestEnabled\": true\n",
    "}\n",
    "```\n",
    "\n",
    "### Additional Plugins:\n",
    "\n",
    "- **Pytest Test Explorer**:\n",
    "   If you want a more feature-rich experience, you can install the **\"Pytest Test Explorer\"** extension. It integrates with the **Test Explorer UI** extension, making it easier to explore, run, and debug tests from a test explorer window.\n",
    "\n",
    "### Conclusion:\n",
    "The **Python** extension by Microsoft is the most commonly used VS Code plugin for running single Pytest tests. It provides excellent integration, and you can easily run individual tests using CodeLens, the Testing Sidebar, or the Command Palette.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Running pytests from command line**\n",
    "## **Running selected test files using pytest**\n",
    "## **Running selected test methods based on matching keywords**\n",
    "\n",
    "Running Pytest from the command line is simple and straightforward. You can execute your tests and even specify various options to customize how Pytest runs. Below are the basic and more advanced ways to run Pytests from the command line:\n",
    "\n",
    "### 1. **Basic Command to Run All Tests**:\n",
    "To run all test files in the current directory and its subdirectories:\n",
    "```bash\n",
    "pytest\n",
    "```\n",
    "\n",
    "### 2. **Run a Specific Test File**:\n",
    "You can specify a particular test file to run:\n",
    "```bash\n",
    "pytest test_file.py\n",
    "```\n",
    "For example:\n",
    "```bash\n",
    "pytest test_example.py\n",
    "```\n",
    "\n",
    "### 3. **Run a Specific Test Function**:\n",
    "To run a specific test function within a file:\n",
    "```bash\n",
    "pytest test_file.py::test_function\n",
    "```\n",
    "For example:\n",
    "```bash\n",
    "pytest test_example.py::test_addition_function\n",
    "```\n",
    "\n",
    "### 4. **Run Tests in a Specific Directory**:\n",
    "To run all tests in a specific directory:\n",
    "```bash\n",
    "pytest path/to/directory/\n",
    "```\n",
    "\n",
    "### 5. **Run Tests Matching a Pattern**:\n",
    "You can run tests that match a specific pattern. For instance, to run all tests whose filenames start with `test_add`:\n",
    "```bash\n",
    "pytest -k \"test_add\"\n",
    "```\n",
    "The `-k` option allows you to select tests based on their names, filtering out others.\n",
    "\n",
    "### 6. **Run Tests Verbosely**:\n",
    "For more detailed output, use the `-v` (verbose) flag:\n",
    "```bash\n",
    "pytest -v\n",
    "```\n",
    "\n",
    "### 7. **Run Tests and Show Output for Print Statements**:\n",
    "If you want to see print statements from your tests in the console output, use the `-s` flag:\n",
    "```bash\n",
    "pytest -s\n",
    "```\n",
    "\n",
    "### 8. **Run Tests with Detailed Failures**:\n",
    "To show a more detailed report of failures (with the entire stack trace), use the `-vv` flag (extra verbose):\n",
    "```bash\n",
    "pytest -vv\n",
    "```\n",
    "\n",
    "### 9. **Stop after First Failure**:\n",
    "To stop the test run after the first failure, use the `-x` flag:\n",
    "```bash\n",
    "pytest -x\n",
    "```\n",
    "\n",
    "### 10. **Run Tests in Parallel**:\n",
    "If you want to run tests in parallel, you can use the `pytest-xdist` plugin with the `-n` flag to specify the number of processes:\n",
    "```bash\n",
    "pytest -n 4\n",
    "```\n",
    "This runs your tests in parallel using 4 processes.\n",
    "\n",
    "### 11. **Generate a Test Report (JUnit XML)**:\n",
    "You can generate a test report in JUnit XML format, useful for continuous integration systems:\n",
    "```bash\n",
    "pytest --junitxml=report.xml\n",
    "```\n",
    "\n",
    "### 12. **Running with a Custom Configuration File**:\n",
    "If you have a custom configuration file (e.g., `pytest.ini`, `tox.ini`, or `setup.cfg`), Pytest will automatically pick up settings from it when running tests:\n",
    "```bash\n",
    "pytest\n",
    "```\n",
    "\n",
    "### 13. **Run with Coverage (Using pytest-cov Plugin)**:\n",
    "To check code coverage while running tests, use the `pytest-cov` plugin:\n",
    "```bash\n",
    "pytest --cov=path/to/module\n",
    "```\n",
    "\n",
    "### 14. **Passing Arguments to Test Functions**:\n",
    "If you are using Pytest's `@pytest.mark.parametrize`, you can specify the arguments directly in the test function call:\n",
    "```bash\n",
    "pytest test_example.py::test_function[param]\n",
    "```\n",
    "\n",
    "### 15. **Run Tests with a Maximum Failures Limit**:\n",
    "To specify a maximum number of failures before stopping:\n",
    "```bash\n",
    "pytest --maxfail=3\n",
    "```\n",
    "\n",
    "### 16. **Run Tests with Output Capture Disabled**:\n",
    "If you want Pytest not to capture output from your tests (e.g., logs or print statements), use the `-s` option:\n",
    "```bash\n",
    "pytest -s\n",
    "```\n",
    "\n",
    "### 17. **Run Tests available in folder**:\n",
    "If you want Pytest to run all test available in folder then navigate to folder and then run py.test or for more details py.test -v.\n",
    "To see print statements in test : py.test -v -s:\n",
    "```bash\n",
    "py.test \n",
    "py.test -v\n",
    "py.test -v -s\n",
    "```\n",
    "\n",
    "### Example of Running Pytest from Command Line:\n",
    "\n",
    "- Run all tests:\n",
    "  ```bash\n",
    "  pytest\n",
    "  ```\n",
    "- Run tests in a specific folder:\n",
    "  ```bash\n",
    "  py.test \n",
    "  py.test -v\n",
    "  py.test -v -s\n",
    "  ```\n",
    "- Run tests in a specific file:\n",
    "  ```bash\n",
    "  pytest test_calculator.py\n",
    "  ```\n",
    "- Run a specific test:\n",
    "  ```bash\n",
    "  pytest test_calculator.py::test_add\n",
    "  ```\n",
    "\n",
    "By combining these options, you can customize the way Pytest runs your tests from the command line.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **wPytest Tags Mechanism to run tests based on functionality**\n",
    "## **Failing and Skipping tests with Annotations using Pytest**\n",
    "## **what is \"mark\" in pytest**\n",
    "\n",
    "In **Pytest**, `mark` refers to **custom markers** that allow you to categorize and selectively run tests based on different labels or tags. Markers are annotations you can add to your test functions to group them, indicate certain behaviors, or provide additional metadata for tests. They can be built-in or custom-defined.\n",
    "\n",
    "### Key Features of Pytest Markers:\n",
    "1. **Selective Test Execution**: Run specific sets of tests (e.g., slow tests, database tests, etc.).\n",
    "2. **Parametrization**: Use markers to pass different sets of inputs to a test.\n",
    "3. **Skipping or Expecting Failures**: Skip certain tests or mark tests as expected to fail.\n",
    "\n",
    "### 1. **Built-in Pytest Markers**:\n",
    "\n",
    "Pytest includes several built-in markers, such as:\n",
    "\n",
    "#### a. **@pytest.mark.skip**:\n",
    "This marker is used to skip a specific test.\n",
    "```python\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.skip(reason=\"Not implemented yet\")\n",
    "def test_addition():\n",
    "    assert 1 + 1 == 2\n",
    "```\n",
    "\n",
    "#### b. **@pytest.mark.skipif(condition, reason)**:\n",
    "Skip a test if a certain condition is met (e.g., specific Python version).\n",
    "```python\n",
    "@pytest.mark.skipif(sys.platform == 'win32', reason=\"Doesn't run on Windows\")\n",
    "def test_platform_dependent_code():\n",
    "    assert some_code()\n",
    "```\n",
    "\n",
    "#### c. **@pytest.mark.xfail**:\n",
    "Mark a test as expected to fail. If the test fails, it will not be counted as a failure.\n",
    "```python\n",
    "@pytest.mark.xfail\n",
    "def test_function_expected_to_fail():\n",
    "    assert 1 + 1 == 3\n",
    "```\n",
    "\n",
    "### 2. **Custom Markers**:\n",
    "\n",
    "You can create your own markers to categorize and run tests selectively. For example, you might want to mark tests as `slow`, `database`, or `api`.\n",
    "\n",
    "#### a. **Defining Custom Markers**:\n",
    "To define custom markers, you need to add them to the `pytest.ini` configuration file to avoid warnings. For example:\n",
    "```ini\n",
    "# pytest.ini\n",
    "[pytest]\n",
    "markers =\n",
    "    slow: marks tests as slow (deselect with '-m \"not slow\"')\n",
    "    database: marks tests as related to database\n",
    "```\n",
    "\n",
    "#### b. **Applying Custom Markers**:\n",
    "You can apply custom markers to your test functions:\n",
    "```python\n",
    "@pytest.mark.slow\n",
    "def test_large_data_processing():\n",
    "    pass\n",
    "\n",
    "@pytest.mark.database\n",
    "def test_database_connection():\n",
    "    pass\n",
    "```\n",
    "\n",
    "### 3. **Running Marked Tests**:\n",
    "Once you mark your tests, you can run them selectively using the `-m` option with the `pytest` command. For example, to run only the `slow` tests:\n",
    "```bash\n",
    "pytest -m slow\n",
    "```\n",
    "\n",
    "Or, to run tests that are **not** slow:\n",
    "```bash\n",
    "pytest -m \"not slow\"\n",
    "```\n",
    "\n",
    "### 4. **Parametrization with Markers**:\n",
    "Markers can also be used for test parameterization to run the same test with different input values.\n",
    "```python\n",
    "@pytest.mark.parametrize(\"input, expected\", [(1, 2), (3, 4)])\n",
    "def test_addition(input, expected):\n",
    "    assert input + 1 == expected\n",
    "```\n",
    "\n",
    "### Example of Using Pytest Markers:\n",
    "\n",
    "#### Defining the marker:\n",
    "```python\n",
    "@pytest.mark.api\n",
    "def test_api_endpoint():\n",
    "    response = requests.get(\"https://example.com/api\")\n",
    "    assert response.status_code == 200\n",
    "```\n",
    "\n",
    "#### Running only the marked tests:\n",
    "```bash\n",
    "pytest -m api\n",
    "```\n",
    "\n",
    "### 5. **Combining Multiple Markers**:\n",
    "You can combine multiple markers when running tests. For example, if you want to run both `slow` and `database` tests:\n",
    "```bash\n",
    "pytest -m \"slow or database\"\n",
    "```\n",
    "\n",
    "### Summary:\n",
    "- **Markers** allow you to categorize, skip, or expect failures for your tests.\n",
    "- **Built-in markers** (like `skip`, `skipif`, `xfail`) help control test execution.\n",
    "- **Custom markers** allow you to label tests and run them selectively.\n",
    "- Custom markers must be defined in the `pytest.ini` file.\n",
    "  \n",
    "Markers make it easier to manage and execute specific sets of tests, making your test suite more organized and manageable.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **What are fixtures and importance of their Hooks in Pytest**\n",
    "## **Different scopes of fixtures and their related annotations to setup Pre and Post conditions on the Test**\n",
    "\n",
    "In **Pytest**, **fixtures** are a powerful feature that provide a way to set up and clean up the state or environment before and after tests are executed. They help in organizing test code, reusing setup code, and ensuring the proper initialization of resources such as databases, APIs, or files.\n",
    "\n",
    "Fixtures can be used to share setup logic among multiple tests and ensure that the required resources are available for the test to run, making them more maintainable, modular, and clean.\n",
    "\n",
    "### Key Features of Fixtures in Pytest:\n",
    "1. **Reusability**: You can define a fixture once and use it across multiple test functions.\n",
    "2. **Modularity**: You can break down complex setups into smaller, independent components.\n",
    "3. **Automatic Invocation**: Fixtures are automatically invoked by Pytest when specified in a test.\n",
    "4. **Scope**: You can define the scope of a fixture to control its lifetime (e.g., per test, module, or session).\n",
    "\n",
    "### 1. **Basic Example of a Pytest Fixture**:\n",
    "\n",
    "A fixture can be created using the `@pytest.fixture` decorator, and it is passed as an argument to the test function where it will be used.\n",
    "\n",
    "```python\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture\n",
    "def setup_data():\n",
    "    data = {\"name\": \"John\", \"age\": 30}\n",
    "    return data\n",
    "\n",
    "def test_check_name(setup_data):\n",
    "    assert setup_data[\"name\"] == \"John\"\n",
    "\n",
    "def test_check_age(setup_data):\n",
    "    assert setup_data[\"age\"] == 30\n",
    "```\n",
    "\n",
    "In this example:\n",
    "- `setup_data` is a fixture that prepares some data (a dictionary in this case).\n",
    "- The test functions `test_check_name` and `test_check_age` use the fixture by simply including it as an argument.\n",
    "- The fixture is automatically executed before each test that uses it.\n",
    "\n",
    "### 2. **Fixture Scope**:\n",
    "\n",
    "By default, fixtures have a **function scope**, meaning they are created and executed for each test function. However, you can change the fixture's scope to one of the following:\n",
    "- `function` (default): The fixture is executed once per test function.\n",
    "- `class`: The fixture is executed once per test class.\n",
    "- `module`: The fixture is executed once per test module.\n",
    "- `session`: The fixture is executed once per entire test session (useful for long-lived resources like databases).\n",
    "\n",
    "#### Example with Different Fixture Scopes:\n",
    "\n",
    "```python\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture(scope=\"module\")\n",
    "def setup_module_data():\n",
    "    print(\"\\nSetting up module data\")\n",
    "    return {\"db\": \"connected\"}\n",
    "\n",
    "@pytest.fixture(scope=\"function\")\n",
    "def setup_function_data():\n",
    "    print(\"\\nSetting up function data\")\n",
    "    return {\"user\": \"Alice\"}\n",
    "\n",
    "def test_check_db_connection(setup_module_data):\n",
    "    assert setup_module_data[\"db\"] == \"connected\"\n",
    "\n",
    "def test_check_user_data(setup_function_data):\n",
    "    assert setup_function_data[\"user\"] == \"Alice\"\n",
    "```\n",
    "\n",
    "In this example:\n",
    "- `setup_module_data` runs only once for all tests in the module due to its `module` scope.\n",
    "- `setup_function_data` runs before each individual test due to its `function` scope.\n",
    "\n",
    "### 3. **Using `yield` for Teardown**:\n",
    "\n",
    "In cases where you need to do **teardown** or cleanup after the test is done (e.g., closing a database connection or file), you can use `yield` in the fixture. The code after the `yield` statement is executed after the test is finished.\n",
    "\n",
    "#### Example with Teardown:\n",
    "\n",
    "```python\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture\n",
    "def setup_teardown():\n",
    "    print(\"\\nSetting up resources\")\n",
    "    yield \"resource\"\n",
    "    print(\"\\nTearing down resources\")\n",
    "\n",
    "def test_using_resource(setup_teardown):\n",
    "    assert setup_teardown == \"resource\"\n",
    "```\n",
    "\n",
    "In this example:\n",
    "- The setup part runs before the test.\n",
    "- The code after `yield` runs after the test for cleanup (teardown).\n",
    "\n",
    "### 4. **Parameterized Fixtures**:\n",
    "\n",
    "You can **parameterize** fixtures to run the same test multiple times with different data or setups. This is useful for testing a variety of inputs or configurations.\n",
    "\n",
    "#### Example with Parameterized Fixture:\n",
    "\n",
    "```python\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture(params=[10, 20, 30])\n",
    "def setup_numbers(request):\n",
    "    return request.param\n",
    "\n",
    "def test_number_is_even(setup_numbers):\n",
    "    assert setup_numbers % 2 == 0\n",
    "```\n",
    "\n",
    "In this example:\n",
    "- The test will run three times, once for each parameter value (`10`, `20`, and `30`).\n",
    "- The `request.param` object provides the current parameter value.\n",
    "\n",
    "### 5. **Fixture Dependencies**:\n",
    "\n",
    "Fixtures can **depend on other fixtures**, allowing you to build complex setups by composing multiple fixtures together.\n",
    "\n",
    "#### Example with Dependent Fixtures:\n",
    "\n",
    "```python\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture\n",
    "def setup_db():\n",
    "    print(\"\\nConnecting to DB\")\n",
    "    return \"DB Connection\"\n",
    "\n",
    "@pytest.fixture\n",
    "def setup_user(setup_db):\n",
    "    print(f\"\\nCreating user with {setup_db}\")\n",
    "    return {\"username\": \"user1\"}\n",
    "\n",
    "def test_user_creation(setup_user):\n",
    "    assert setup_user[\"username\"] == \"user1\"\n",
    "```\n",
    "\n",
    "In this example:\n",
    "- `setup_user` depends on `setup_db`.\n",
    "- The database connection (`setup_db`) is created before the user is set up.\n",
    "\n",
    "### 6. **Autouse Fixtures**:\n",
    "\n",
    "You can mark a fixture as **autouse**, meaning it will automatically be invoked for all tests, even if it's not explicitly passed as an argument.\n",
    "\n",
    "#### Example with Autouse Fixture:\n",
    "\n",
    "```python\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture(autouse=True)\n",
    "def auto_setup():\n",
    "    print(\"\\nAuto setup before each test\")\n",
    "\n",
    "def test_first():\n",
    "    assert 1 == 1\n",
    "\n",
    "def test_second():\n",
    "    assert 2 == 2\n",
    "```\n",
    "\n",
    "In this example:\n",
    "- The `auto_setup` fixture runs automatically before each test.\n",
    "\n",
    "### Summary:\n",
    "\n",
    "- **Fixtures** provide a way to set up and clean up resources before and after tests.\n",
    "- They are reusable, modular, and can have different scopes (function, module, class, session).\n",
    "- They support **teardown** with `yield` and can be **parameterized** for running tests with different data.\n",
    "- Fixtures can **depend** on other fixtures, enabling complex setups.\n",
    "- They can also be **autouse** to automatically run without being explicitly called.\n",
    "\n",
    "Fixtures enhance code organization, making tests more manageable, reusable, and clean.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **@pytest.mark.usefixtures**\n",
    "\n",
    "In **Pytest**, `@pytest.mark.usefixtures` is a decorator that allows you to explicitly specify which **fixtures** should be used in a test function, class, or module. It is an alternative to passing the fixture directly as an argument to the test function. This can be useful when you want to use a fixture for its side effects (such as setting up a database, starting a server, etc.), but you don't need to directly reference the fixture within the test function itself.\n",
    "\n",
    "### Key Use Cases for `usefixtures`:\n",
    "- When the fixture is needed for **setup or teardown** purposes but is not directly used in the test function.\n",
    "- When applying fixtures to **classes** or **modules**, affecting multiple test functions at once.\n",
    "- To make tests **cleaner** by avoiding unused fixture arguments in function signatures.\n",
    "\n",
    "### Syntax:\n",
    "```python\n",
    "@pytest.mark.usefixtures(\"fixture_name\")\n",
    "def test_function():\n",
    "    # Test logic goes here\n",
    "```\n",
    "\n",
    "You can apply it to individual test functions, classes, or even the whole module.\n",
    "\n",
    "### Example 1: Applying `usefixtures` to a Test Function\n",
    "\n",
    "```python\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture\n",
    "def setup_environment():\n",
    "    print(\"\\nSetting up environment\")\n",
    "\n",
    "@pytest.mark.usefixtures(\"setup_environment\")\n",
    "def test_sample():\n",
    "    print(\"Running test_sample\")\n",
    "    assert True\n",
    "```\n",
    "\n",
    "#### Explanation:\n",
    "- `setup_environment` is a fixture that prints a message when it is called.\n",
    "- `@pytest.mark.usefixtures(\"setup_environment\")` ensures that `setup_environment` runs before `test_sample`, even though `setup_environment` is not passed as an argument to `test_sample`.\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "Setting up environment\n",
    "Running test_sample\n",
    "```\n",
    "\n",
    "### Example 2: Applying `usefixtures` to a Class\n",
    "\n",
    "You can also apply the `usefixtures` decorator to an entire class, and it will be applied to all test methods within that class.\n",
    "\n",
    "```python\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture\n",
    "def login():\n",
    "    print(\"\\nLogging in as user\")\n",
    "\n",
    "@pytest.mark.usefixtures(\"login\")\n",
    "class TestUserActions:\n",
    "    \n",
    "    def test_view_profile(self):\n",
    "        print(\"Testing profile view\")\n",
    "    \n",
    "    def test_edit_profile(self):\n",
    "        print(\"Testing profile edit\")\n",
    "```\n",
    "\n",
    "#### Explanation:\n",
    "- The `login` fixture will run before each test method (`test_view_profile` and `test_edit_profile`), even though it is not passed as an argument to any of these methods.\n",
    "- The `usefixtures` decorator is applied at the class level, so all test methods in the class will automatically use the fixture.\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "Logging in as user\n",
    "Testing profile view\n",
    "\n",
    "Logging in as user\n",
    "Testing profile edit\n",
    "```\n",
    "\n",
    "### Example 3: Applying `usefixtures` to a Module\n",
    "\n",
    "You can apply `usefixtures` at the module level by putting it at the top of your test module. This will apply the fixture to all tests in the module.\n",
    "\n",
    "```python\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture\n",
    "def initialize_db():\n",
    "    print(\"\\nInitializing the database\")\n",
    "\n",
    "@pytest.mark.usefixtures(\"initialize_db\")\n",
    "def test_insert_data():\n",
    "    print(\"Testing data insertion\")\n",
    "\n",
    "@pytest.mark.usefixtures(\"initialize_db\")\n",
    "def test_fetch_data():\n",
    "    print(\"Testing data fetching\")\n",
    "```\n",
    "\n",
    "#### Explanation:\n",
    "- Both `test_insert_data` and `test_fetch_data` will run the `initialize_db` fixture, which sets up the database, even though it’s not passed as an argument.\n",
    "\n",
    "### When to Use `usefixtures`:\n",
    "\n",
    "1. **Fixture with Side Effects**: Use `usefixtures` when the fixture only performs setup or teardown tasks and is not directly required in the test logic.\n",
    "   \n",
    "2. **Cleaner Test Function**: It helps you keep test function signatures clean by avoiding unnecessary fixture arguments.\n",
    "\n",
    "3. **Class-Level or Module-Level Setup**: When you want to ensure certain setup steps apply to multiple tests, but don't want to pass the fixture to each test function manually.\n",
    "\n",
    "### Summary:\n",
    "- `@pytest.mark.usefixtures` is used to ensure that a fixture is executed before a test or set of tests without passing the fixture as an argument.\n",
    "- It is useful for applying fixtures that have side effects or when you want to apply a fixture across multiple test functions, classes, or entire modules.\n",
    "- It keeps test function signatures cleaner by eliminating the need to include unused fixture arguments.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **How fixtures can be configured in Conftest file for better readability**\n",
    "\n",
    "In Pytest, **`conftest.py`** and **`pytest.ini`** are configuration files that help in customizing and organizing the test suite. They serve different purposes but work together to make testing more efficient and flexible.\n",
    "\n",
    "### 1. **`conftest.py`**:\n",
    "\n",
    "The **`conftest.py`** file is a special configuration file for Pytest that allows you to share fixtures, hooks, and other settings across multiple test files. It’s typically used to define **fixtures** or **hooks** that can be used by all test files in a directory or subdirectories without the need for importing them explicitly.\n",
    "\n",
    "#### Key Features of `conftest.py`:\n",
    "- **Local to a Directory**: The configuration and fixtures in `conftest.py` apply to all tests in the same directory and any subdirectories.\n",
    "- **No Imports Needed**: You don't have to import the fixtures defined in `conftest.py` into each test file; they are automatically available.\n",
    "- **Hierarchical Behavior**: You can have multiple `conftest.py` files in different directories, and Pytest will use the closest one in the directory hierarchy for that particular test.\n",
    "\n",
    "#### Common Use Cases:\n",
    "- Defining fixtures shared across multiple test modules.\n",
    "- Adding custom test hooks (e.g., modifying test execution behavior).\n",
    "- Setting up logging, database connections, or other shared resources.\n",
    "\n",
    "#### Example of `conftest.py`:\n",
    "```python\n",
    "# conftest.py\n",
    "import pytest\n",
    "\n",
    "# A shared fixture for all test files in this directory and subdirectories\n",
    "@pytest.fixture\n",
    "def setup_database():\n",
    "    print(\"\\nSetting up database connection\")\n",
    "    db = \"Connected to DB\"\n",
    "    yield db\n",
    "    print(\"\\nTearing down database connection\")\n",
    "```\n",
    "\n",
    "#### Example Usage in a Test File:\n",
    "```python\n",
    "# test_example.py\n",
    "def test_db_connection(setup_database):\n",
    "    assert setup_database == \"Connected to DB\"\n",
    "```\n",
    "\n",
    "In this example:\n",
    "- `setup_database` is a fixture defined in `conftest.py`, and it is automatically available to any test in the directory and subdirectories where `conftest.py` is located.\n",
    "\n",
    "### 2. **`pytest.ini`**:\n",
    "\n",
    "The **`pytest.ini`** file is a configuration file that defines project-wide settings for Pytest. It allows you to configure various Pytest behaviors, such as custom markers, test paths, and default command-line options.\n",
    "\n",
    "#### Key Features of `pytest.ini`:\n",
    "- **Global Configuration**: The settings in `pytest.ini` apply to the entire test suite.\n",
    "- **Custom Markers**: You can define custom markers to label tests.\n",
    "- **Command-line Options**: Set default Pytest options like verbosity, test paths, and more.\n",
    "- **Test Discovery**: Configure how Pytest discovers test files (e.g., by setting specific patterns).\n",
    "\n",
    "#### Example of `pytest.ini`:\n",
    "```ini\n",
    "# pytest.ini\n",
    "[pytest]\n",
    "markers =\n",
    "    slow: marks tests as slow (use '-m slow' to run)\n",
    "    database: marks tests as database-related\n",
    "addopts = -v --maxfail=3\n",
    "testpaths = tests\n",
    "```\n",
    "\n",
    "#### Key Sections:\n",
    "1. **markers**:\n",
    "   - Defines custom markers (e.g., `slow`, `database`) so you can tag and selectively run tests.\n",
    "   \n",
    "2. **addopts**:\n",
    "   - Specifies additional default command-line options. In this example, `-v` enables verbose output, and `--maxfail=3` stops the test run after 3 failures.\n",
    "\n",
    "3. **testpaths**:\n",
    "   - Defines where Pytest should look for tests. Here, it is set to look inside the `tests/` folder.\n",
    "\n",
    "### Example Use Case for `pytest.ini`:\n",
    "- You want to mark certain tests as \"slow\" and configure Pytest to stop after 3 test failures. By defining this in `pytest.ini`, all tests in your project will adhere to this behavior without specifying it manually on the command line.\n",
    "\n",
    "### Summary:\n",
    "\n",
    "- **`conftest.py`**: A Python file used to share fixtures, hooks, and setup logic across multiple test files in a directory or subdirectory. It’s automatically discovered by Pytest.\n",
    "- **`pytest.ini`**: A configuration file to set project-wide Pytest options, including custom markers, default command-line options, and test discovery paths.\n",
    "\n",
    "Together, `conftest.py` and `pytest.ini` help organize and streamline your test suite, making it easier to manage complex testing setups.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **In what scenario one will be forced to pass fixture name though you have declared it globally?**\n",
    "\n",
    "In Pytest, even though fixtures can be defined globally (in `conftest.py` or at the module level), there are certain scenarios where you may still need to pass the fixture name explicitly as an argument in the test function. Here's when and why you'd do that:\n",
    "\n",
    "### 1. **When the Test Requires the Return Value of the Fixture**:\n",
    "If your test needs to use the return value of a fixture directly, you must pass the fixture name as an argument to the test function. Merely marking it globally (e.g., with `usefixtures`) won’t allow you to access the fixture’s return value.\n",
    "\n",
    "#### Example:\n",
    "```python\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture\n",
    "def db_connection():\n",
    "    return \"Database Connection Established\"\n",
    "\n",
    "def test_query(db_connection):\n",
    "    assert db_connection == \"Database Connection Established\"\n",
    "```\n",
    "\n",
    "In this case, the test function `test_query` uses the return value of the `db_connection` fixture, so the fixture must be passed as an argument.\n",
    "\n",
    "### 2. **When the Fixture Is Parameterized**:\n",
    "If a fixture is parameterized, it needs to be passed as an argument to allow the test function to run with different values for each parameter.\n",
    "\n",
    "#### Example:\n",
    "```python\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture(params=[\"chrome\", \"firefox\", \"safari\"])\n",
    "def browser(request):\n",
    "    return request.param\n",
    "\n",
    "def test_browser_compatibility(browser):\n",
    "    print(f\"Testing on {browser}\")\n",
    "```\n",
    "\n",
    "Here, the `browser` fixture is parameterized to test with different browsers. You need to pass the fixture as an argument to access the parameterized value for each test run.\n",
    "\n",
    "### 3. **When Using Fixtures in Test Logic**:\n",
    "If your test logic directly depends on the value or output of the fixture, or if you need to assert on the result or output of the fixture, passing it explicitly is necessary.\n",
    "\n",
    "#### Example:\n",
    "```python\n",
    "@pytest.fixture\n",
    "def user():\n",
    "    return {\"username\": \"test_user\", \"email\": \"user@example.com\"}\n",
    "\n",
    "def test_user_login(user):\n",
    "    assert user[\"username\"] == \"test_user\"\n",
    "```\n",
    "\n",
    "Here, the test needs the `user` data to validate the login logic, so the fixture is passed as an argument.\n",
    "\n",
    "### 4. **When Using Multiple Fixtures**:\n",
    "If a test requires multiple fixtures, you must pass them as arguments explicitly in the function definition.\n",
    "\n",
    "#### Example:\n",
    "```python\n",
    "@pytest.fixture\n",
    "def setup_database():\n",
    "    return \"DB setup complete\"\n",
    "\n",
    "@pytest.fixture\n",
    "def setup_cache():\n",
    "    return \"Cache setup complete\"\n",
    "\n",
    "def test_application(setup_database, setup_cache):\n",
    "    assert setup_database == \"DB setup complete\"\n",
    "    assert setup_cache == \"Cache setup complete\"\n",
    "```\n",
    "\n",
    "Each fixture that the test function needs must be explicitly included as a parameter.\n",
    "\n",
    "### 5. **When You Need to Override a Fixture**:\n",
    "In some cases, you may need to override a fixture in certain tests. You must pass the fixture as an argument explicitly in the test function to override or modify its behavior locally.\n",
    "\n",
    "#### Example:\n",
    "```python\n",
    "@pytest.fixture\n",
    "def user():\n",
    "    return {\"username\": \"default_user\", \"email\": \"default@example.com\"}\n",
    "\n",
    "def test_override_user(user):\n",
    "    user[\"username\"] = \"custom_user\"\n",
    "    assert user[\"username\"] == \"custom_user\"\n",
    "```\n",
    "\n",
    "Here, `test_override_user` modifies the default fixture value, so the fixture is passed explicitly to the function.\n",
    "\n",
    "### 6. **When You Want to Control the Fixture Scope**:\n",
    "Fixtures with larger scopes (e.g., module, session) are often used for setting up global resources. However, if a specific test needs to alter or use a different resource, you’ll need to pass the fixture to the test function to control how and when the resource is used.\n",
    "\n",
    "#### Example:\n",
    "```python\n",
    "@pytest.fixture(scope=\"module\")\n",
    "def shared_resource():\n",
    "    return \"Resource for the whole module\"\n",
    "\n",
    "def test_use_shared_resource(shared_resource):\n",
    "    assert shared_resource == \"Resource for the whole module\"\n",
    "```\n",
    "\n",
    "The fixture is passed because you want to control its usage within the test function, even though it has a global scope.\n",
    "\n",
    "### 7. **When You Need Access to Fixture Internals (like `request` or `caplog`)**:\n",
    "Some fixtures, like `request`, provide special capabilities such as accessing parameters or metadata about the test itself. These fixtures need to be passed as arguments to the test function for accessing their internals.\n",
    "\n",
    "#### Example:\n",
    "```python\n",
    "@pytest.fixture\n",
    "def my_fixture(request):\n",
    "    print(f\"Running {request.node.name}\")\n",
    "    return \"fixture_value\"\n",
    "\n",
    "def test_with_request(my_fixture):\n",
    "    assert my_fixture == \"fixture_value\"\n",
    "```\n",
    "\n",
    "In this case, the `request` object is only accessible when the fixture is passed explicitly to the test function.\n",
    "\n",
    "### Summary:\n",
    "You need to pass fixture names explicitly as arguments in the following scenarios:\n",
    "- When your test function needs to **use the fixture’s return value**.\n",
    "- When your fixture is **parameterized** to run with multiple inputs.\n",
    "- When you’re using **multiple fixtures** in one test.\n",
    "- When you want to **override** or modify the fixture locally.\n",
    "- When you need to **control the fixture’s scope** or have a fixture with a broader scope.\n",
    "- When you want to access **special fixture features**, like `request` or `caplog`.\n",
    "\n",
    "In these cases, the fixture must be passed as an argument so that its result or value can be used directly within the test function logic.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
